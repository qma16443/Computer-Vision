{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"font-family:Georgia;\n",
    "              font-size:2.5vw;\n",
    "              color:lightblue;\n",
    "              font-style:bold;\n",
    "              text-align:center;\n",
    "              background:url('./Animations/Title Background.gif') no-repeat center;\n",
    "              background-size:cover)\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Histograms of Oriented Gradients (HOG)\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "<h1 style = \"text-align:left\">Introduction</h1>\n",
    "\n",
    "正如我们在ORB算法中看到的那样，我们可以使用图像中的关键点来进行基于关键点的匹配，以此来检测图像中的对象。如果你想检测具有许多不受背景影响的一致内部特征的对象，这些类型的算法就会非常有用。比如，这些算法适用于人脸检测，因为人脸具有许多不受图像背景影响的一致内部特征，例如眼睛、鼻子和嘴巴。然而，如果要尝试进行更一般的对象识别（例如，图像中的行人检测），这些类型的算法就不会那么有用了。原因是行人与人脸不同，没有与人脸一样的内部特征，毕竟每个行人的体形和走路风格都不同（见图1）。这意味着每个行人都有不同的内部特征，因此我们需要一些可以用于更一般地描述行人的方法。\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "  <img src = \"./Animations/pedestrians.jpeg\" width = \"100%\" style = \"border: thin silver solid; padding: 10px\">\n",
    "      <figcaption style = \"text-align:left; font-style:italic\">Fig. 1. - Pedestrians.</figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "其中，有一种方法是尝试通过轮廓来检测行人。通过轮廓（边界）可以检测到图像中的对象，但这种方法非常具有难度，因为我们必须处理背景和前景之间的对比，而完成这一点是相当困难的。例如，假设你想要检测在白色建筑物前行走的图像中的行人，并且她穿着白色外套和黑色裤子（见图2）。我们可以在图2中看到，由于图像的背景大多是白色的，因此黑色裤子具有非常高的对比度，但是白色外套具有非常低的对比度。在这种情况下，非常容易就可以检测到裤子的边缘，但要检测外套的边缘，就会非常困难。在这个时候，就需要使用**HOG** 了。HOG代表**方向梯度直方图** ，它是由Navneet Dalal和Bill Triggs于2005年首次提出的。\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "  <img src = \"./Animations/woman.jpg\" width = \"100%\" style = \"border: thin silver solid; padding: 10px\">\n",
    "      <figcaption style = \"text-align:left; font-style:italic\">Fig. 2. - High and Low Contrast.</figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "HOG算法的工作原理是通过创建图像中梯度方向分布的直方图，然后以非常特殊的方式对它们进行归一化。即使在对比度非常低的情况下，这种特殊的归一化也使得HOG在检测物体边缘方面非常有效。这些归一化的直方图会被放在一个特征向量中，称为HOG描述子。HOG可用于训练机器学习算法，如支持向量机（SVM），使其根据它们的边界（边缘）检测图像中的对象 。由于其巨大的成功和可靠性，HOG已成为用于对象检测的计算机视觉中最广泛使用的算法之一。\n",
    "\n",
    "\n",
    "在这个notebook中，你将要学习的内容如下：\n",
    "\n",
    "* HOG算法的工作原理\n",
    "* 如何使用OpenCV创建HOG描述子\n",
    "* 如何可视化HOG描述子。\n",
    "\n",
    "# HOG算法\n",
    "\n",
    "顾名思义，HOG算法是一种基于从图像梯度的方向创建直方图的算法。 HOG算法是通过一系列步骤实现的，具体如下：\n",
    "\n",
    "1. 对于某个特定对象的图像，设置一个可以覆盖图像中整个对象的检测窗口或者你感兴趣的区域（参见图3）。\n",
    "\n",
    "2. 计算检测窗口中每个像素的梯度的大小和方向。\n",
    "\n",
    "3. 将检测窗口划分为连接的像素*单元格* ，其中，所有单元格的大小相同（参见图3）。该单元格的大小是一个自由参数，通常选择它的目的在于匹配想要检测的特征的范围。例如，在64×128像素检测窗口中，6至8像素宽的正方形单元格适合于检测人体肢体。\n",
    "\n",
    "4. 为每个单元格创建直方图，首先将每个单元格中所有像素的渐变方向分组为特定数量的方向（角度）区间（bin）；然后将每个角度区间中梯度的梯度大小相加（见图3）。直方图中的区间数是一个自由参数，通常设置为9个角度区间。\n",
    "\n",
    "5. 将相邻的单元格分组成*块*（见图3）。每个块中的单元格数是一个自由参数，所有块必须具有相同的大小。每个块之间的距离（称为步长）是一个自由参数，但通常设置为块大小的一半，在这种情况下，你将会获得重叠块（*请查看下面的视频*）。这样，HOG算法会根据经验更好地与重叠块一起运行。\n",
    "\n",
    "6. 使用每个块中包含的单元格来归一化该块中的单元格直方图（参见图3）。如果你有重叠块，这说明大多数单元格将根据不同的块进行归一化（*请查看下面的视频*）。因此，相同的单元格可以具有几种不同的归一化。\n",
    "\n",
    "7. 将所有块中的所有归一化直方图收集到称为HOG描述子的单个特征向量中。\n",
    "\n",
    "8. 使用来自相同类型对象的大量图像的结果HOG描述子来训练机器学习算法（例如SVM），进而检测图像中那些类型的对象。 例如，你可以使用来自行人的大量图像的HOG描述子来训练SVM，进而检测图像中的行人。其中，训练是通过你想要在图像中检测到的对象的正反面示例完成的。\n",
    "\n",
    "9. 训练完SVM之后，你需要使用滑动窗口方法来尝试检测和定位图像中的对象。 要想检测图像中的对象，你需要找到看起来类似于SVM所学习的HOG类型的图像部分。\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "  <img src = \"./Animations/HOG Diagram2.png\" width = \"100%\" style = \"border: thin silver solid; padding: 1px\">\n",
    "      <figcaption style = \"text-align:left; font-style:italic\">Fig. 3. - HOG Diagram.</figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "<figure>\n",
    "<video src = \"./Animations/HOG Animation - Medium.mp4\" width=\"100%\" controls autoplay loop> </video>\n",
    "<figcaption style = \"text-align:left; font-style:italic\">Vid. 1. - HOG Animation.</figcaption>\n",
    "</figure> \n",
    "\n",
    "# 为什么HOG算法如此有效\n",
    "\n",
    "如上所述，HOG通过在称为*单元格*的图像的局部部分中添加特定方向的梯度的大小来创建直方图。这样做，我们保证了更强的梯度会对其各自的角度区间的大小产生更多影响，同时由噪声导致的较弱与随机定向梯度的影响被最小化。总之，直方图会以这种方式告诉我们每个单元格的主导梯度方向。\n",
    "\n",
    "\n",
    "### 处理对比 \n",
    "\n",
    "现在，由于局部照明的变化以及背景和前景之间的对比度，主导方向的梯度差异会非常大。\n",
    "\n",
    "为了弄清楚背景与前景对比度差异，HOG算法尝试在本地检测边缘。为了做到这一点，它定义了一组称为**块**的单元格，并使用这个本地单元格组对该直方图进行归一化。通过局部归一化，HOG算法可以非常可靠地检测每个块中的边缘。这就叫做**块归一化**。\n",
    "\n",
    "除了使用块归一化之外，HOG算法还使用重叠块来提高其性能。通过使用重叠块，每个单元格向最终HOG描述子贡献若干独立分量，其中每个分量对应于相对于不同块归一化的单元格。这似乎是多余的，但是，经验证明，通过相对于不同的本地块对每个单元格进行几次归一化，HOG算法的性能会显著提高。\n",
    "\n",
    "### 加载图像并导入资源\n",
    "\n",
    "要创建HOG描述子，第一步是将所需的包加载到Python中并加载图像。\n",
    "\n",
    "我们首先使用OpenCV加载三角形图块的图像。因为，`cv2.imread()`函数会将图像加载为BGR，而我们需要将图像转换为RGB，这样我们就可以使用正确的颜色显示它。与之前一样，我们会将BGR图像转换为灰度图像进行分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original image has shape:  (250, 250, 3)\n",
      "The gray scale image has shape:  (250, 250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b49d45e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [17.0, 7.0]\n",
    "\n",
    "# Load the image \n",
    "image = cv2.imread('./images/triangle_tile.jpeg')\n",
    "\n",
    "# Convert the original image to RGB\n",
    "original_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert the original image to gray scale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Print the shape of the original and gray scale images\n",
    "print('The original image has shape: ', original_image.shape)\n",
    "print('The gray scale image has shape: ', gray_image.shape)\n",
    "\n",
    "# Display the images\n",
    "plt.subplot(121)\n",
    "plt.imshow(original_image)\n",
    "plt.title('Original Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.title('Gray Scale Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建HOG描述子\n",
    "\n",
    "我们将使用OpenCV的`HOGDescriptor`类来创建HOG描述子， 使用`HOGDescriptor()`函数设置HOG描述子的参数。`HOGDescriptor()`函数的参数及其默认值如下：\n",
    "\n",
    "`cv2.HOGDescriptor(win_size = (64, 128),  \n",
    "                  block_size = (16, 16),  \n",
    "                  block_stride = (8, 8),  \n",
    "                  cell_size = (8, 8),  \n",
    "                  nbins = 9,  \n",
    "                  win_sigma = DEFAULT_WIN_SIGMA,  \n",
    "                  threshold_L2hys = 0.2,  \n",
    "                  gamma_correction = true,  \n",
    "                  nlevels = DEFAULT_NLEVELS)`\n",
    "\n",
    "参数：\n",
    "\n",
    "* **win_size** – *Size*  \n",
    "  检测窗口的大小（以像素为单位）（*高度，宽度*）。定义一个感兴趣的区域。它必须是单元格尺寸的整数倍。\n",
    "\n",
    "\n",
    "* **block_size** – *Size*  \n",
    "  块大小（以像素为单位）（*宽度，高度*）。定义每个块中有多少个单元格。它必须是单元格尺寸的整数倍，并且必须小于检测窗口。块越小，你将获得的细节越详细。\n",
    "\n",
    "\n",
    "* **block_stride** – *Size*  \n",
    "  以像素为单位块步长（*水平，垂直*）。它必须是单元格尺寸的整数倍。 `block_stride`定义了相邻块之间的距离，例如，水平8个像素和垂直8个像素。`block_stride`越长，算法就会运行得越快（因为评估的块会越少），但算法也可能不再运行。\n",
    "\n",
    "\n",
    "* **cell_size** – *Size*  \n",
    "  单元格大小，以像素为单位（*宽度，高度*）。确定格单元的大小。单元格越小，你将获得的细节越详细。\n",
    "\n",
    "\n",
    "* **nbins** – *int*  \n",
    "  直方图的区间数。确定用于制作直方图的角度区间数量。使用的区间越多，就可以获取更多的渐变方向。 HOG使用无符号渐变，因此角度区间的值将介于0和180度之间。\n",
    "\n",
    "\n",
    "* **win_sigma** – *double*  \n",
    "  高斯平滑窗口参数。通过在计算直方图之前对每个像素应用高斯空间窗口来平滑块边缘附近的像素，从而改善HOG算法的性能。\n",
    "\n",
    "\n",
    "* **threshold_L2hys** – *double*  \n",
    "   L2-Hys（Lowe式限幅L2范数）归一化方法收缩率。 L2-Hys方法用于归一化块，它由L2范数和剪切以及重归一化组成。限幅会将每个块的描述子向量的最大值限制为具有给定阈值的值（默认为0.2）。限幅之后，如*IJCV*，60（2）：91-110,2004中所述，重新归一化描述子矢量。\n",
    "\n",
    "\n",
    "* **gamma_correction** – *bool*  \n",
    "  用于指定是否需要伽马校正预处理的标志。执行伽马校正可以在一定程度上提高HOG算法的性能。\n",
    "\n",
    "\n",
    "* **nlevels** – *int*  \n",
    "  检测窗口增加的最大数量。\n",
    "\n",
    "我们可以看到，`cv2.HOGDescriptor()`函数支持各种参数。前几个参数（`block_size, block_stride, cell_size`以及`nbins`）是最有可能更改的参数。其他参数都可以放心地保留其默认值，这样你会获得很不错的结果。\n",
    "\n",
    "在下面的代码中，我们将使用 `cv2.HOGDescriptor()`函数来设置单元格大小、块大小、块步长以及HOG描述子的直方图区间数。然后，我们将使用`.compute(image)`方法计算给定`image`的HOG描述子（特征向量）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters for our HOG descriptor\n",
    "\n",
    "# Cell Size in pixels (width, height). Must be smaller than the size of the detection window\n",
    "# and must be chosen so that the resulting Block Size is smaller than the detection window.\n",
    "cell_size = (6, 6)\n",
    "\n",
    "# Number of cells per block in each direction (x, y). Must be chosen so that the resulting\n",
    "# Block Size is smaller than the detection window\n",
    "num_cells_per_block = (2, 2)\n",
    "\n",
    "# Block Size in pixels (width, height). Must be an integer multiple of Cell Size.\n",
    "# The Block Size must be smaller than the detection window\n",
    "block_size = (num_cells_per_block[0] * cell_size[0],\n",
    "              num_cells_per_block[1] * cell_size[1])\n",
    "\n",
    "# Calculate the number of cells that fit in our image in the x and y directions\n",
    "x_cells = gray_image.shape[1] // cell_size[0]\n",
    "y_cells = gray_image.shape[0] // cell_size[1]\n",
    "\n",
    "# Horizontal distance between blocks in units of Cell Size. Must be an integer and it must\n",
    "# be set such that (x_cells - num_cells_per_block[0]) / h_stride = integer.\n",
    "h_stride = 1\n",
    "\n",
    "# Vertical distance between blocks in units of Cell Size. Must be an integer and it must\n",
    "# be set such that (y_cells - num_cells_per_block[1]) / v_stride = integer.\n",
    "v_stride = 1\n",
    "\n",
    "# Block Stride in pixels (horizantal, vertical). Must be an integer multiple of Cell Size\n",
    "block_stride = (cell_size[0] * h_stride, cell_size[1] * v_stride)\n",
    "\n",
    "# Number of gradient orientation bins\n",
    "num_bins = 9        \n",
    "\n",
    "\n",
    "# Specify the size of the detection window (Region of Interest) in pixels (width, height).\n",
    "# It must be an integer multiple of Cell Size and it must cover the entire image. Because\n",
    "# the detection window must be an integer multiple of cell size, depending on the size of\n",
    "# your cells, the resulting detection window might be slightly smaller than the image.\n",
    "# This is perfectly ok.\n",
    "win_size = (x_cells * cell_size[0] , y_cells * cell_size[1])\n",
    "\n",
    "# Print the shape of the gray scale image for reference\n",
    "print('\\nThe gray scale image has shape: ', gray_image.shape)\n",
    "print()\n",
    "\n",
    "# Print the parameters of our HOG descriptor\n",
    "print('HOG Descriptor Parameters:\\n')\n",
    "print('Window Size:', win_size)\n",
    "print('Cell Size:', cell_size)\n",
    "print('Block Size:', block_size)\n",
    "print('Block Stride:', block_stride)\n",
    "print('Number of Bins:', num_bins)\n",
    "print()\n",
    "\n",
    "# Set the parameters of the HOG descriptor using the variables defined above\n",
    "hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, num_bins)\n",
    "\n",
    "# Compute the HOG Descriptor for the gray scale image\n",
    "hog_descriptor = hog.compute(gray_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  HOG描述子中的元素数量\n",
    "\n",
    "由此得到的HOG描述子（特征向量）包含来自在一个长向量中连接的检测窗口中的所有块的所有单元格的归一化直方图。因此，HOG特征向量的大小将由检测窗口中的块总数乘以每个块的单元格数乘以定向区间的数量来得出，公式如下：\n",
    "\n",
    "<span class=\"mathquill\">\n",
    "\\begin{equation}\n",
    "\\mbox{total_elements} = (\\mbox{total_number_of_blocks})\\mbox{ } \\times \\mbox{ } (\\mbox{number_cells_per_block})\\mbox{ } \\times \\mbox{ } (\\mbox{number_of_bins})\n",
    "\\end{equation}\n",
    "</span>\n",
    "\n",
    "如果没有重叠块（*即* ` block_stride`等于`block_size`），则可以通过将检测窗口的大小除以块大小来计算块的总数。但是，在一般情况下，必须考虑到我们有重叠块的事实。要想知道一般情况下的块总数（*即* 对于任何`block_stride`和`block_size`），可以使用下面给出的公式：\n",
    "\n",
    "<span class=\"mathquill\">\n",
    "\\begin{equation}\n",
    "\\mbox{Total}_i = \\left( \\frac{\\mbox{block_size}_i}{\\mbox{block_stride}_i} \\right)\\left( \\frac{\\mbox{window_size}_i}{\\mbox{block_size}_i} \\right) - \\left [\\left( \\frac{\\mbox{block_size}_i}{\\mbox{block_stride}_i} \\right) - 1 \\right]; \\mbox{  for  } i = x,y\n",
    "\\end{equation}\n",
    "</span>\n",
    "\n",
    "其中，<span class =“mathquill”> Total$_x$ </span>，是沿检测窗口宽度的块总数，<span class =“mathquill”> Total$_y$</span>，是沿着检测窗口高度的块总数。这个 <span class =“mathquill”> Total$_x$ </span>和<span class =“mathquill”> Total$_y$</span>公式考虑了重叠产生的额外块。在计算<span class =“mathquill”> Total$_x$ </span>和<span class =“mathquill”> Total$_y$</span>之后，我们可以通过<span class =“mathquill“> Total$_x$ 乘以 Total$_y$</span>来获取检测窗口中的块总数。其实，上述公式可以进行相当大的简化，因为`block_size`，`block_stride`和`window_size`都是根据`cell_size`定义的。通过进行适当的替换和删除，上述公式简化为：\n",
    "\n",
    "<span class=\"mathquill\">\n",
    "\\begin{equation}\n",
    "\\mbox{Total}_i = \\left(\\frac{\\mbox{cells}_i - \\mbox{num_cells_per_block}_i}{N_i}\\right) + 1\\mbox{  }; \\mbox{  for  } i = x,y\n",
    "\\end{equation}\n",
    "</span>\n",
    "\n",
    "其中，<span class =“mathquill”> cells$_x$</span>是沿检测窗口宽度的单元格总数，<span class =“mathquill”> cells$_y$</span>，是沿检测窗口高度的单元格总数。 <span class =“mathquill”> $N_x$</span>是以`cell_size`为单位的水平块步长，<span class =“mathquill”>$N_y$</span>是以cell_size`cell_size`为单位的垂直块步长。\n",
    "\n",
    "接下来，让我们计算一下HOG特征向量的元素数量应该是多少，并检查它是否与上面计算的HOG描述子的形状相匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of blocks along the width of the detection window\n",
    "tot_bx = np.uint32(((x_cells - num_cells_per_block[0]) / h_stride) + 1)\n",
    "\n",
    "# Calculate the total number of blocks along the height of the detection window\n",
    "tot_by = np.uint32(((y_cells - num_cells_per_block[1]) / v_stride) + 1)\n",
    "\n",
    "# Calculate the total number of elements in the feature vector\n",
    "tot_els = (tot_bx) * (tot_by) * num_cells_per_block[0] * num_cells_per_block[1] * num_bins\n",
    "\n",
    "# Print the total number of elements the HOG feature vector should have\n",
    "print('\\nThe total number of elements in the HOG Feature Vector should be: ',\n",
    "      tot_bx, 'x',\n",
    "      tot_by, 'x',\n",
    "      num_cells_per_block[0], 'x',\n",
    "      num_cells_per_block[1], 'x',\n",
    "      num_bins, '=',\n",
    "      tot_els)\n",
    "\n",
    "# Print the shape of the HOG Descriptor to see that it matches the above\n",
    "print('\\nThe HOG Descriptor has shape:', hog_descriptor.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化HOG描述子\n",
    "\n",
    "我们可以通过将与每个单元格相关联的直方图绘制为矢量集合来可视化HOG描述子。为此，我们将直方图中的每个区间绘制为单个向量，其大小由区间的高度而定，其方向由与其关联的角度区间而定。由于任何给定的单元格，可能有多个与之关联的直方图。由于重叠块的存在，我们将选择平均分配每个单元格的所有直方图，这样便于为每个单元格生成单个直方图。\n",
    "\n",
    "要可视化HOG描述子，OpenCV没有简单的方法可用，因此我们必须先进行一些操作才能使其可视化。这要从改变HOG描述子开始，这样可以使我们的计算更容易。然后，我们将计算每个单元格的平均直方图，最后我们将直方图区间转换为矢量。只要有了矢量，就可以为图像中的每个单元格绘制相应的矢量图。\n",
    "\n",
    "下面的代码会生成一个交互式图，你可以与之进行交互。该图包含：\n",
    "* 灰度图像，\n",
    "* HOG描述子（特征向量），\n",
    "* HOG描述子的放大部分，\n",
    "* 所选单元格的直方图。\n",
    "\n",
    "**你可以通过灰度图像或HOG描述子图像上的任意位置来选择特定单元格。** 单击任一图像后，将出现一个*洋红色*矩形，它会显示你选择的单元。缩放窗口将显示所选单元格周围的HOG描述子的一个放大版本，而直方图将显示所选单元格的相应直方图。交互式窗口底部还有按钮，你可以选择其他功能，例如平移，并根据需要提供了保存图形的选项。点击Home按钮，会将图形返回到其默认值。\n",
    "\n",
    "**注意**: 如果你在优达学城工作区中运行此notebook，则交互式图大约会有2秒的延迟。这就是说，如果单击图像进行放大，则交互图的刷新将需要大约2秒钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import copy\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [9.8, 9]\n",
    "\n",
    "# Reshape the feature vector to [blocks_y, blocks_x, num_cells_per_block_x, num_cells_per_block_y, num_bins].\n",
    "# The blocks_x and blocks_y will be transposed so that the first index (blocks_y) referes to the row number\n",
    "# and the second index to the column number. This will be useful later when we plot the feature vector, so\n",
    "# that the feature vector indexing matches the image indexing.\n",
    "hog_descriptor_reshaped = hog_descriptor.reshape(tot_bx,\n",
    "                                                 tot_by,\n",
    "                                                 num_cells_per_block[0],\n",
    "                                                 num_cells_per_block[1],\n",
    "                                                 num_bins).transpose((1, 0, 2, 3, 4))\n",
    "\n",
    "# Print the shape of the feature vector for reference\n",
    "print('The feature vector has shape:', hog_descriptor.shape)\n",
    "\n",
    "# Print the reshaped feature vector\n",
    "print('The reshaped feature vector has shape:', hog_descriptor_reshaped.shape)\n",
    "\n",
    "# Create an array that will hold the average gradients for each cell\n",
    "ave_grad = np.zeros((y_cells, x_cells, num_bins))\n",
    "\n",
    "# Print the shape of the ave_grad array for reference\n",
    "print('The average gradient array has shape: ', ave_grad.shape) \n",
    "\n",
    "# Create an array that will count the number of histograms per cell\n",
    "hist_counter = np.zeros((y_cells, x_cells, 1))\n",
    "\n",
    "# Add up all the histograms for each cell and count the number of histograms per cell\n",
    "for i in range (num_cells_per_block[0]):\n",
    "    for j in range(num_cells_per_block[1]):\n",
    "        ave_grad[i:tot_by + i,\n",
    "                 j:tot_bx + j] += hog_descriptor_reshaped[:, :, i, j, :]\n",
    "        \n",
    "        hist_counter[i:tot_by + i,\n",
    "                     j:tot_bx + j] += 1\n",
    "\n",
    "# Calculate the average gradient for each cell\n",
    "ave_grad /= hist_counter\n",
    "   \n",
    "# Calculate the total number of vectors we have in all the cells.\n",
    "len_vecs = ave_grad.shape[0] * ave_grad.shape[1] * ave_grad.shape[2]\n",
    "\n",
    "# Create an array that has num_bins equally spaced between 0 and 180 degress in radians.\n",
    "deg = np.linspace(0, np.pi, num_bins, endpoint = False)\n",
    "\n",
    "# Each cell will have a histogram with num_bins. For each cell, plot each bin as a vector (with its magnitude\n",
    "# equal to the height of the bin in the histogram, and its angle corresponding to the bin in the histogram). \n",
    "# To do this, create rank 1 arrays that will hold the (x,y)-coordinate of all the vectors in all the cells in the\n",
    "# image. Also, create the rank 1 arrays that will hold all the (U,V)-components of all the vectors in all the\n",
    "# cells in the image. Create the arrays that will hold all the vector positons and components.\n",
    "U = np.zeros((len_vecs))\n",
    "V = np.zeros((len_vecs))\n",
    "X = np.zeros((len_vecs))\n",
    "Y = np.zeros((len_vecs))\n",
    "\n",
    "# Set the counter to zero\n",
    "counter = 0\n",
    "\n",
    "# Use the cosine and sine functions to calculate the vector components (U,V) from their maginitudes. Remember the \n",
    "# cosine and sine functions take angles in radians. Calculate the vector positions and magnitudes from the\n",
    "# average gradient array\n",
    "for i in range(ave_grad.shape[0]):\n",
    "    for j in range(ave_grad.shape[1]):\n",
    "        for k in range(ave_grad.shape[2]):\n",
    "            U[counter] = ave_grad[i,j,k] * np.cos(deg[k])\n",
    "            V[counter] = ave_grad[i,j,k] * np.sin(deg[k])\n",
    "        \n",
    "            X[counter] = (cell_size[0] / 2) + (cell_size[0] * i)\n",
    "            Y[counter] = (cell_size[1] / 2) + (cell_size[1] * j)\n",
    "        \n",
    "            counter = counter + 1\n",
    "\n",
    "# Create the bins in degress to plot our histogram. \n",
    "angle_axis = np.linspace(0, 180, num_bins, endpoint = False)\n",
    "angle_axis += ((angle_axis[1] - angle_axis[0]) / 2)\n",
    "\n",
    "# Create a figure with 4 subplots arranged in 2 x 2\n",
    "fig, ((a,b),(c,d)) = plt.subplots(2,2)\n",
    "\n",
    "# Set the title of each subplot\n",
    "a.set(title = 'Gray Scale Image\\n(Click to Zoom)')\n",
    "b.set(title = 'HOG Descriptor\\n(Click to Zoom)')\n",
    "c.set(title = 'Zoom Window', xlim = (0, 18), ylim = (0, 18), autoscale_on = False)\n",
    "d.set(title = 'Histogram of Gradients')\n",
    "\n",
    "# Plot the gray scale image\n",
    "a.imshow(gray_image, cmap = 'gray')\n",
    "a.set_aspect(aspect = 1)\n",
    "\n",
    "# Plot the feature vector (HOG Descriptor)\n",
    "b.quiver(Y, X, U, V, color = 'white', headwidth = 0, headlength = 0, scale_units = 'inches', scale = 5)\n",
    "b.invert_yaxis()\n",
    "b.set_aspect(aspect = 1)\n",
    "b.set_facecolor('black')\n",
    "\n",
    "# Define function for interactive zoom\n",
    "def onpress(event):\n",
    "    \n",
    "    #Unless the left mouse button is pressed do nothing\n",
    "    if event.button != 1:\n",
    "        return\n",
    "    \n",
    "    # Only accept clicks for subplots a and b\n",
    "    if event.inaxes in [a, b]:\n",
    "        \n",
    "        # Get mouse click coordinates\n",
    "        x, y = event.xdata, event.ydata\n",
    "        \n",
    "        # Select the cell closest to the mouse click coordinates\n",
    "        cell_num_x = np.uint32(x / cell_size[0])\n",
    "        cell_num_y = np.uint32(y / cell_size[1])\n",
    "        \n",
    "        # Set the edge coordinates of the rectangle patch\n",
    "        edgex = x - (x % cell_size[0])\n",
    "        edgey = y - (y % cell_size[1])\n",
    "        \n",
    "        # Create a rectangle patch that matches the the cell selected above        \n",
    "        rect = patches.Rectangle((edgex, edgey),\n",
    "                                  cell_size[0], cell_size[1],\n",
    "                                  linewidth = 1,\n",
    "                                  edgecolor = 'magenta',\n",
    "                                  facecolor='none')\n",
    "        \n",
    "        # A single patch can only be used in a single plot. Create copies\n",
    "        # of the patch to use in the other subplots\n",
    "        rect2 = copy.copy(rect)\n",
    "        rect3 = copy.copy(rect)\n",
    "        \n",
    "        # Update all subplots\n",
    "        a.clear()\n",
    "        a.set(title = 'Gray Scale Image\\n(Click to Zoom)')\n",
    "        a.imshow(gray_image, cmap = 'gray')\n",
    "        a.set_aspect(aspect = 1)\n",
    "        a.add_patch(rect)\n",
    "\n",
    "        b.clear()\n",
    "        b.set(title = 'HOG Descriptor\\n(Click to Zoom)')\n",
    "        b.quiver(Y, X, U, V, color = 'white', headwidth = 0, headlength = 0, scale_units = 'inches', scale = 5)\n",
    "        b.invert_yaxis()\n",
    "        b.set_aspect(aspect = 1)\n",
    "        b.set_facecolor('black')\n",
    "        b.add_patch(rect2)\n",
    "\n",
    "        c.clear()\n",
    "        c.set(title = 'Zoom Window')\n",
    "        c.quiver(Y, X, U, V, color = 'white', headwidth = 0, headlength = 0, scale_units = 'inches', scale = 1)\n",
    "        c.set_xlim(edgex - cell_size[0], edgex + (2 * cell_size[0]))\n",
    "        c.set_ylim(edgey - cell_size[1], edgey + (2 * cell_size[1]))\n",
    "        c.invert_yaxis()\n",
    "        c.set_aspect(aspect = 1)\n",
    "        c.set_facecolor('black')\n",
    "        c.add_patch(rect3)\n",
    "\n",
    "        d.clear()\n",
    "        d.set(title = 'Histogram of Gradients')\n",
    "        d.grid()\n",
    "        d.set_xlim(0, 180)\n",
    "        d.set_xticks(angle_axis)\n",
    "        d.set_xlabel('Angle')\n",
    "        d.bar(angle_axis,\n",
    "              ave_grad[cell_num_y, cell_num_x, :],\n",
    "              180 // num_bins,\n",
    "              align = 'center',\n",
    "              alpha = 0.5,\n",
    "              linewidth = 1.2,\n",
    "              edgecolor = 'k')\n",
    "\n",
    "        fig.canvas.draw()\n",
    "\n",
    "# Create a connection between the figure and the mouse click\n",
    "fig.canvas.mpl_connect('button_press_event', onpress)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 了解直方图\n",
    "\n",
    "下面，让我们看一下上图的几个快照，看看所选单元格的直方图是否有意义。首先，看一个在三角形内部而不是边缘附近的一个单元格：\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "  <img src = \"./Animations/snapshot1.png\" width = \"70%\" style = \"border: thin silver solid; padding: 1px\">\n",
    "      <figcaption style = \"text-align:center; font-style:italic\">Fig. 4. - Histograms Inside a Triangle.</figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "在这个示例中，由于三角形几乎都是相同的颜色，因此在所选单元格中不应存在任何主导梯度。我们在缩放窗口和直方图中也可以清楚地看到，情况确实如此。梯度有很多，但没有一个在另一个上占明显的主导地位。\n",
    "\n",
    "现在，让我们看一下靠近水平边缘的一个单元格：\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "  <img src = \"./Animations/snapshot2.png\" width = \"70%\" style = \"border: thin silver solid; padding: 1px\">\n",
    "      <figcaption style = \"text-align:center; font-style:italic\">Fig. 5. - Histograms Near a Horizontal Edge.</figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "请牢记，边缘是图像中强度变化很突然的一个区域。在这些区域，我们将在某个特定方向上具有高强度梯度。这正是我们在所选单元格的相应直方图和缩放窗口中看到的内容。在缩放窗口中，我们可以看到主导梯度呈几乎90度的向上趋势，因为这是强度急剧变化的方向。因此，我们应该期望直方图中的90度区域比其他区域更强。实际上，这就是我们所看到的。\n",
    "\n",
    "接下来，让我们看一下靠近垂直边缘的一个单元格：\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "  <img src = \"./Animations/snapshot3.png\" width = \"70%\" style = \"border: thin silver solid; padding: 1px\">\n",
    "      <figcaption style = \"text-align:center; font-style:italic\">Fig. 6. - Histograms Near a Vertical Edge.</figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "在这个示例中，我们希望该单元格中的主导梯度是水平的，接近180度，因为这是强度急剧变化的方向。因此，我们应该期望直方图中的170度区域会强烈支配其他区域。实际上，这就是我们在直方图中看到的，但我们也看到该单元格中还有另一个显性梯度，即10度区间中的梯度。原因在于HOG算法使用无符号梯度，这意味着0度和180度被认为是相同的。因此，当创建直方图时，160度和180度之间的角度与10度区间和170度区间成比例。这就会导致在垂直边缘附近的单元格中，存在两个主导梯度，而不是只有一个。\n",
    "\n",
    "最后，让我们看一下靠近对角线边缘的一个单元格。\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "  <img src = \"./Animations/snapshot4.png\" width = \"70%\" style = \"border: thin silver solid; padding: 1px\">\n",
    "      <figcaption style = \"text-align:center; font-style:italic\">Fig. 7. - Histograms Near a Diagonal Edge.</figcaption>\n",
    "</figure> \n",
    "<br>\n",
    "\n",
    "要理解我们所看到的东西，首先，我们要知道，梯度有一个x分量和一个y分量，就像矢量一样。因此，一个梯度的最终方向将由其分量的矢量和而定。出于这个原因，在垂直边缘上，梯度都是水平的，因为它们只有一个x分量，如图4所示。而在水平边缘上，梯度都是垂直的，因为它们只有一个y分量，如图3所示。因此，在对角线边缘，梯度将会是对角线，因为x和y分量都是非零。由于图像中的对角线边缘接近45度，我们应该期望在50度区间中看到一个主导的梯度方向。实际上，这就是我们在直方图中看到的，但是，如图4所示，我们看到有两个主导梯度而不是一个。其原因在于，创建直方图时，靠近区间边缘的角度成比例地给相邻区间提供贡献。例如，角度为40度的梯度位于30度和50度区间的中间。因此，梯度的大小被均匀地分成30度和50度的区间。这就会导致在对角线边缘附近的单元中，存在两个主导梯度，而不是只有一个。\n",
    "\n",
    "现在你已经了解了HOG的实现方式，接下来，在工作区中找到名为*Examples*的notebook。你可以在那里为各种图像的HOG描述子设置自己的参数。祝你学得开心哦！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
